{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7f1dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# from transformers import RobertaTokenizer, TFRobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49be7f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Importing relevant packages\n",
    "import glob\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import csv\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from itertools import islice\n",
    "import seaborn as sns\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "568b58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39024f7c",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "feaf6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('../data/training_set.txt', sep = ' ', header = None)\n",
    "training.columns = ['source_id', 'target_id', 'Y']\n",
    "\n",
    "testing = pd.read_csv('../data/testing_set.txt', sep = ' ', header = None)\n",
    "testing.columns = ['source_id', 'target_id']\n",
    "\n",
    "node_info = pd.read_csv('../data/node_information.csv', header = None)\n",
    "node_info.columns  = ['id', 'year', 'title', 'authors', 'journal_name', 'abstract']\n",
    "node_info['authors'] = node_info['authors'].fillna(value='')\n",
    "node_info['journal_name'] = node_info['journal_name'].fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "439e37a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(615512, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac9e20",
   "metadata": {},
   "source": [
    "## Create nodes and edges file - No need to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "abb9ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = node_info.loc[:,['id', 'title']]\n",
    "nodes_df.to_csv('../data/nodes.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "329cca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = training.loc[training['Y'] == 1,['source_id','target_id'] ]\n",
    "edges_df.to_csv('../data/edges.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233f7363",
   "metadata": {},
   "source": [
    "## Process node info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f4b7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27770, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e05c30e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry and duality</td>\n",
       "      <td>Paul S. Aspinwall</td>\n",
       "      <td></td>\n",
       "      <td>these are notes based on lectures given at tas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain walls and massive gauged supergravity p...</td>\n",
       "      <td>M. Cvetic, H. Lu, C.N. Pope</td>\n",
       "      <td>Class.Quant.Grav.</td>\n",
       "      <td>we point out that massive gauged supergravity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment on metric fluctuations in brane worlds</td>\n",
       "      <td>Y.S. Myung, Gungwon Kang</td>\n",
       "      <td></td>\n",
       "      <td>recently ivanov and volovich hep-th 9912242 cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirrors and thermodynamic paradoxes</td>\n",
       "      <td>Adam D. Helfer</td>\n",
       "      <td>Phys.Rev.</td>\n",
       "      <td>quantum fields responding to moving mirrors ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundles of chiral blocks and boundary conditio...</td>\n",
       "      <td>J. Fuchs, C. Schweigert</td>\n",
       "      <td></td>\n",
       "      <td>proceedings of lie iii clausthal july 1999 var...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1001  2000              compactification geometry and duality   \n",
       "1  1002  2000  domain walls and massive gauged supergravity p...   \n",
       "2  1003  2000     comment on metric fluctuations in brane worlds   \n",
       "3  1004  2000         moving mirrors and thermodynamic paradoxes   \n",
       "4  1005  2000  bundles of chiral blocks and boundary conditio...   \n",
       "\n",
       "                       authors       journal_name  \\\n",
       "0            Paul S. Aspinwall                      \n",
       "1  M. Cvetic, H. Lu, C.N. Pope  Class.Quant.Grav.   \n",
       "2     Y.S. Myung, Gungwon Kang                      \n",
       "3               Adam D. Helfer          Phys.Rev.   \n",
       "4      J. Fuchs, C. Schweigert                      \n",
       "\n",
       "                                            abstract  \n",
       "0  these are notes based on lectures given at tas...  \n",
       "1  we point out that massive gauged supergravity ...  \n",
       "2  recently ivanov and volovich hep-th 9912242 cl...  \n",
       "3  quantum fields responding to moving mirrors ha...  \n",
       "4  proceedings of lie iii clausthal july 1999 var...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9d7af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets_authors(name):\n",
    "    if name == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    name = re.sub(r'\\(.*?\\)',\"\",name)\n",
    "    clean_name = []\n",
    "    for x in name.split(\",\"):\n",
    "        if x == \"\" or x == \" \":\n",
    "            continue\n",
    "            \n",
    "        if x.find('(') == -1:\n",
    "            clean_name.append(x.strip())\n",
    "            continue\n",
    "            \n",
    "        clean_name.append(x.replace(x[x.find('('):], \"\").strip())\n",
    "    return \",\".join(clean_name)             \n",
    "\n",
    "def process_title(title):\n",
    "    title_tokens = [token for token in title.split(\" \") if token not in stop_words]\n",
    "    title_tokens = [lemmatizer.lemmatize(token) for token in title_tokens]\n",
    "    return \" \".join(title_tokens)\n",
    "\n",
    "def process_abstract(abstract):\n",
    "    abstract_tokens = [token for token in abstract.split(\" \") if token not in stop_words]\n",
    "    abstract_tokens = [lemmatizer.lemmatize(token) for token in abstract_tokens]\n",
    "    return \" \".join(abstract_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c6c0272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_node_info():\n",
    "    \n",
    "    # Process authors\n",
    "    node_info['authors'] = node_info['authors'].apply(lambda names: remove_brackets_authors(names).lower()) \n",
    "    \n",
    "    # Process journal name\n",
    "    node_info['journal_name'] = node_info['journal_name'].apply(lambda jn: jn[:-1].lower() if \",\" in jn else jn.lower())\n",
    "    \n",
    "    # Process title\n",
    "    node_info['title'] = node_info['title'].apply(lambda title: process_title(title))\n",
    "    \n",
    "    # Process abstract\n",
    "    node_info['abstract'] = node_info['abstract'].apply(lambda title: process_abstract(title))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e31cf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_node_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12af5d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry duality</td>\n",
       "      <td>paul s. aspinwall</td>\n",
       "      <td></td>\n",
       "      <td>note based lecture given tasi99 review geometr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain wall massive gauged supergravity potential</td>\n",
       "      <td>m. cvetic,h. lu,c.n. pope</td>\n",
       "      <td>class.quant.grav.</td>\n",
       "      <td>point massive gauged supergravity potential ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment metric fluctuation brane world</td>\n",
       "      <td>y.s. myung,gungwon kang</td>\n",
       "      <td></td>\n",
       "      <td>recently ivanov volovich hep-th 9912242 claime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirror thermodynamic paradox</td>\n",
       "      <td>adam d. helfer</td>\n",
       "      <td>phys.rev.</td>\n",
       "      <td>quantum field responding moving mirror predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundle chiral block boundary condition cft</td>\n",
       "      <td>j. fuchs,c. schweigert</td>\n",
       "      <td></td>\n",
       "      <td>proceeding lie iii clausthal july 1999 various...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1001  2000                  compactification geometry duality   \n",
       "1  1002  2000  domain wall massive gauged supergravity potential   \n",
       "2  1003  2000             comment metric fluctuation brane world   \n",
       "3  1004  2000                moving mirror thermodynamic paradox   \n",
       "4  1005  2000         bundle chiral block boundary condition cft   \n",
       "\n",
       "                     authors       journal_name  \\\n",
       "0          paul s. aspinwall                      \n",
       "1  m. cvetic,h. lu,c.n. pope  class.quant.grav.   \n",
       "2    y.s. myung,gungwon kang                      \n",
       "3             adam d. helfer          phys.rev.   \n",
       "4     j. fuchs,c. schweigert                      \n",
       "\n",
       "                                            abstract  \n",
       "0  note based lecture given tasi99 review geometr...  \n",
       "1  point massive gauged supergravity potential ex...  \n",
       "2  recently ivanov volovich hep-th 9912242 claime...  \n",
       "3  quantum field responding moving mirror predict...  \n",
       "4  proceeding lie iii clausthal july 1999 various...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9dc8c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info.to_csv(\"../data/updated_node_information.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bef9c",
   "metadata": {},
   "source": [
    "## Process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4df7a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = pd.merge(training, node_info[['id', 'year', 'authors', 'title', 'journal_name', 'abstract']],how='left', left_on='source_id', right_on='id') \\\n",
    ".drop('id', axis=1) \\\n",
    ".rename(columns={\"year\":\"source_year\", 'authors':'source_authors', 'title':'source_title', 'journal_name':'source_jn', 'abstract':'source_abstract'})\n",
    "\n",
    "training = pd.merge(training, node_info[['id', 'year', 'authors', 'title', 'journal_name', 'abstract']],how='left', left_on='target_id', right_on='id') \\\n",
    ".drop('id', axis=1) \\\n",
    ".rename(columns={\"year\":\"target_year\", 'authors':'target_authors', 'title':'target_title', 'journal_name':'target_jn', 'abstract':'target_abstract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e0a71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.merge(testing, node_info[['id', 'year', 'authors', 'title', 'journal_name', 'abstract']],how='left', left_on='source_id', right_on='id') \\\n",
    ".drop('id', axis=1) \\\n",
    ".rename(columns={\"year\":\"source_year\", 'authors':'source_authors', 'title':'source_title', 'journal_name':'source_jn', 'abstract':'source_abstract'})\n",
    "\n",
    "testing = pd.merge(testing, node_info[['id', 'year', 'authors', 'title', 'journal_name', 'abstract']],how='left', left_on='target_id', right_on='id') \\\n",
    ".drop('id', axis=1) \\\n",
    ".rename(columns={\"year\":\"target_year\", 'authors':'target_authors', 'title':'target_title', 'journal_name':'target_jn', 'abstract':'target_abstract'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fda042f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>source_year</th>\n",
       "      <th>source_authors</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_jn</th>\n",
       "      <th>source_abstract</th>\n",
       "      <th>target_year</th>\n",
       "      <th>target_authors</th>\n",
       "      <th>target_title</th>\n",
       "      <th>target_jn</th>\n",
       "      <th>target_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td></td>\n",
       "      <td>an infinite number of potentials surrounding 2...</td>\n",
       "      <td>phys.lett.</td>\n",
       "      <td>we found an infinite number of potentials surr...</td>\n",
       "      <td>1995</td>\n",
       "      <td>won t. kim,julian lee,young jai park</td>\n",
       "      <td>stability analysis of the dilatonic black hole...</td>\n",
       "      <td>phys.lett.</td>\n",
       "      <td>we explicitly show that the net number of degr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9707075</td>\n",
       "      <td>9604178</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>l.e.ibanez,a.m.uranga</td>\n",
       "      <td>d 6 n 1 string vacua and duality</td>\n",
       "      <td></td>\n",
       "      <td>winter school on duality mt sorak korea februa...</td>\n",
       "      <td>1996</td>\n",
       "      <td>atish dabholkar,jaemo park</td>\n",
       "      <td>strings on orientifolds</td>\n",
       "      <td>nucl.phys.</td>\n",
       "      <td>we construct several examples of compactificat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  target_id  Y  source_year         source_authors  \\\n",
       "0    9510123    9502114  1         1995                          \n",
       "1    9707075    9604178  1         1997  l.e.ibanez,a.m.uranga   \n",
       "\n",
       "                                        source_title   source_jn  \\\n",
       "0  an infinite number of potentials surrounding 2...  phys.lett.   \n",
       "1                   d 6 n 1 string vacua and duality               \n",
       "\n",
       "                                     source_abstract  target_year  \\\n",
       "0  we found an infinite number of potentials surr...         1995   \n",
       "1  winter school on duality mt sorak korea februa...         1996   \n",
       "\n",
       "                         target_authors  \\\n",
       "0  won t. kim,julian lee,young jai park   \n",
       "1            atish dabholkar,jaemo park   \n",
       "\n",
       "                                        target_title   target_jn  \\\n",
       "0  stability analysis of the dilatonic black hole...  phys.lett.   \n",
       "1                            strings on orientifolds  nucl.phys.   \n",
       "\n",
       "                                     target_abstract  \n",
       "0  we explicitly show that the net number of degr...  \n",
       "1  we construct several examples of compactificat...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e379d67b",
   "metadata": {},
   "source": [
    "### Year diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a3162e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['year_diff'] = training['source_year'] - training['target_year']\n",
    "training['year_diff'] = training['year_diff'].apply(lambda diff : -1 if diff < 0 else diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c81edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['year_diff'] = testing['source_year'] - testing['target_year']\n",
    "testing['year_diff'] = testing['year_diff'].apply(lambda diff : -1 if diff < 0 else diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82501769",
   "metadata": {},
   "source": [
    "### Common Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6fafa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_authors(source, target):\n",
    "    if source == \"\" or target == \"\":\n",
    "        return 0\n",
    "    source = source.split(\",\")\n",
    "    target = target.split(\",\")\n",
    "    return len(set(source) & (set(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fd65373",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['common_authors'] = training.apply(lambda row: common_authors(row.source_authors, row.target_authors), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "121c1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['source_authors'] = testing['source_authors'].fillna(value='')\n",
    "testing['target_authors'] = testing['target_authors'].fillna(value='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b76b4861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing['common_authors'] = testing.apply(lambda row: common_authors(row.source_authors, row.target_authors), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9123e41",
   "metadata": {},
   "source": [
    "### Same Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90b13e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['same_journal'] = training.apply(lambda row: 1 if row.source_jn != \"\" and row.target_jn != \"\" and row.source_jn == row.target_jn else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31de3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['same_journal'] = testing.apply(lambda row: 1 if row.source_jn != \"\" and row.target_jn != \"\" and row.source_jn == row.target_jn else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd7dbd",
   "metadata": {},
   "source": [
    "### Title and Abstract TFIDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec68eaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize_string(string):\n",
    "    new_string = string.lower().split(\" \")\n",
    "    return [lemmatizer.lemmatize(token) for token in new_string if token not in stop_words]\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_string)\n",
    "tfidf_abstract = vectorizer.fit_transform(node_info[\"abstract\"])\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize_string)\n",
    "tfidf_title = vectorizer.fit_transform(node_info[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825211e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_title = tfidf_title.todense()\n",
    "tfidf_abstract = tfidf_abstract.todense()\n",
    "\n",
    "def compute_similarity(src, trgt, vectorizer):\n",
    "    src_pos = np.where(node_info.id == src)[0].item()\n",
    "    trgt_pos = np.where(node_info.id == trgt)[0].item()\n",
    "    \n",
    "    if vectorizer == 'title':\n",
    "        src = np.asarray(tfidf_title[src_pos])\n",
    "        trgt = np.asarray(tfidf_title[trgt_pos])\n",
    "    elif vectorizer == 'abstract':\n",
    "        src = np.asarray(tfidf_abstract[src_pos])\n",
    "        trgt = np.asarray(tfidf_abstract[trgt_pos])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    return cosine_similarity(src, trgt).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d6a1aff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 490 ms, total: 2min 26s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training['title_similarity'] = training.apply(lambda row: compute_similarity(row.source_id, row.target_id, 'title'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8beda8bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.75 s, sys: 14.5 ms, total: 7.77 s\n",
      "Wall time: 7.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['title_similarity'] = testing.apply(lambda row: compute_similarity(row.source_id, row.target_id, 'title'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31893255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 2.87 s, total: 3min 39s\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training['abstract_similarity'] = training.apply(lambda row: compute_similarity(row.source_id, row.target_id, 'abstract'), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "231aa212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 106 ms, total: 11.5 s\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['abstract_similarity'] = testing.apply(lambda row: compute_similarity(row.source_id, row.target_id, 'abstract'), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cf7eb",
   "metadata": {},
   "source": [
    "### Title and Abstract embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce92eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af3634ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27770, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal_name</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>2000</td>\n",
       "      <td>compactification geometry duality</td>\n",
       "      <td>paul s. aspinwall</td>\n",
       "      <td></td>\n",
       "      <td>note based lecture given tasi99 review geometr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>2000</td>\n",
       "      <td>domain wall massive gauged supergravity potential</td>\n",
       "      <td>m. cvetic,h. lu,c.n. pope</td>\n",
       "      <td>class.quant.grav.</td>\n",
       "      <td>point massive gauged supergravity potential ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>2000</td>\n",
       "      <td>comment metric fluctuation brane world</td>\n",
       "      <td>y.s. myung,gungwon kang</td>\n",
       "      <td></td>\n",
       "      <td>recently ivanov volovich hep-th 9912242 claime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004</td>\n",
       "      <td>2000</td>\n",
       "      <td>moving mirror thermodynamic paradox</td>\n",
       "      <td>adam d. helfer</td>\n",
       "      <td>phys.rev.</td>\n",
       "      <td>quantum field responding moving mirror predict...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>2000</td>\n",
       "      <td>bundle chiral block boundary condition cft</td>\n",
       "      <td>j. fuchs,c. schweigert</td>\n",
       "      <td></td>\n",
       "      <td>proceeding lie iii clausthal july 1999 various...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title  \\\n",
       "0  1001  2000                  compactification geometry duality   \n",
       "1  1002  2000  domain wall massive gauged supergravity potential   \n",
       "2  1003  2000             comment metric fluctuation brane world   \n",
       "3  1004  2000                moving mirror thermodynamic paradox   \n",
       "4  1005  2000         bundle chiral block boundary condition cft   \n",
       "\n",
       "                     authors       journal_name  \\\n",
       "0          paul s. aspinwall                      \n",
       "1  m. cvetic,h. lu,c.n. pope  class.quant.grav.   \n",
       "2    y.s. myung,gungwon kang                      \n",
       "3             adam d. helfer          phys.rev.   \n",
       "4     j. fuchs,c. schweigert                      \n",
       "\n",
       "                                            abstract  \n",
       "0  note based lecture given tasi99 review geometr...  \n",
       "1  point massive gauged supergravity potential ex...  \n",
       "2  recently ivanov volovich hep-th 9912242 claime...  \n",
       "3  quantum field responding moving mirror predict...  \n",
       "4  proceeding lie iii clausthal july 1999 various...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(node_info.shape)\n",
    "node_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e143fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(values):\n",
    "    return roberta_model.encode(values, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "546789ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5f9350f40f4fa0ac05047a90f9d0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5161d43c968c46869b657846d55df933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19h 17min 35s, sys: 1h 4min 41s, total: 20h 22min 17s\n",
      "Wall time: 2h 38min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "title_embeddings = get_embeddings(list(node_info.title))\n",
    "abstract_embeddings = get_embeddings(list(node_info.abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "35a9e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cosine_similarity(src_id, trgt_id, embeddings):\n",
    "    src_idx = node_info[node_info['id']==src_id].index.values.astype(int)[0]\n",
    "    trgt_idx = node_info[node_info['id']==trgt_id].index.values.astype(int)[0]\n",
    "    \n",
    "    if embeddings == \"title\":\n",
    "        src_embed = title_embeddings[src_idx]\n",
    "        trgt_embed = title_embeddings[trgt_idx]\n",
    "        \n",
    "    if embeddings == \"abstract\":\n",
    "        src_embed = abstract_embeddings[src_idx]\n",
    "        trgt_embed = abstract_embeddings[trgt_idx]\n",
    "        \n",
    "    cosine_score = util.cos_sim(src_embed, trgt_embed)\n",
    "    \n",
    "    return cosine_score.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0406c06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 3 µs, total: 8 µs\n",
      "Wall time: 14.8 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "training['title_embed_sim'] = training.apply(lambda row: find_cosine_similarity(row.source_id,row.target_id, \"title\"), axis = 1)\n",
    "training['abstract_embed_sim'] = training.apply(lambda row: find_cosine_similarity(row.source_id,row.target_id, \"abstract\"), axis = 1)\n",
    "\n",
    "testing['title_embed_sim'] = testing.apply(lambda row: find_cosine_similarity(row.source_id,row.target_id, \"title\"), axis = 1)\n",
    "testing['abstract_sembed_sim'] = testing.apply(lambda row: find_cosine_similarity(row.source_id,row.target_id, \"abstract\"), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a2fff4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing.rename(columns={'abstract_sembed_sim':'abstract_embed_sim'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cb867d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source_id', 'target_id', 'source_year', 'source_authors',\n",
       "       'source_title', 'source_jn', 'source_abstract', 'target_year',\n",
       "       'target_authors', 'target_title', 'target_jn', 'target_abstract',\n",
       "       'year_diff', 'common_authors', 'same_journal', 'title_similarity',\n",
       "       'abstract_similarity', 'source_in_centrality', 'source_out_centrality',\n",
       "       'target_in_centrality', 'target_out_centrality',\n",
       "       'source_degree_centrality', 'target_degree_centrality', 'source_k_core',\n",
       "       'target_k_core', 'pref_attach_directed', 'jacc_index',\n",
       "       'pref_attach_undirected', 'common_neighbors', 'adamic_adar',\n",
       "       'distance_nodes', 'distance_nodes2', 'distance_nodes3',\n",
       "       'target_pagerank', 'source_hub_score', 'target_authority_score',\n",
       "       'target_hub_score', 'source_authority_score', 'common_neighbors_b',\n",
       "       'title_embed_sim', 'abstract_embed_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5945146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title_embeds = roberta_model.encode(node_info.title.values, show_progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775b02b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(title_embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b0fc5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.1 s, sys: 242 ms, total: 3.34 s\n",
      "Wall time: 502 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = roberta_model.encode('I like dogs', convert_to_tensor=True)\n",
    "embeddings2 = roberta_model.encode('i do not like dogs', convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec3c1805",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5931638479232788"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f07db6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d48374e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv(\"../data/cleaned_trainig_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad928874",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv(\"../data/cleaned_testing_set.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e14f6e",
   "metadata": {},
   "source": [
    "## Network properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a68cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"../data/cleaned_trainig_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ceb375a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv(\"../data/cleaned_testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0855df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_info= pd.read_csv(\"../data/updated_node_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c68fe5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(node_info.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb0c64af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(615512, 18)\n",
      "(27770, 6)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape)\n",
    "print(node_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8782536a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32648, 17)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a97c43",
   "metadata": {},
   "source": [
    "### Directed Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17d64417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph\n",
    "training_values = training.values.tolist()\n",
    "edges = [(node_pair[0], node_pair[1]) for node_pair in training_values if node_pair[2] == 1]\n",
    "\n",
    "G = nx.DiGraph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aae0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree_centrality = nx.out_degree_centrality(G)\n",
    "in_degree_centrality = nx.in_degree_centrality(G)\n",
    "deg_centrality = nx.degree_centrality(G)\n",
    "# betweeness_centrality = nx.betweenness_centrality(G, k=10)\n",
    "k_core = nx.core_number(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7a24cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 607 ms, total: 28.8 s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training['source_in_centrality'] = training.apply(lambda row: in_degree_centrality[row.source_id], axis = 1)\n",
    "training['source_out_centrality'] = training.apply(lambda row: out_degree_centrality[row.source_id], axis = 1)\n",
    "training['target_in_centrality'] = training.apply(lambda row: in_degree_centrality[row.target_id], axis = 1)\n",
    "training['target_out_centrality'] = training.apply(lambda row: out_degree_centrality[row.target_id], axis = 1)\n",
    "\n",
    "training['source_degree_centrality'] = training.apply(lambda row: deg_centrality[row.source_id], axis = 1)\n",
    "training['target_degree_centrality'] = training.apply(lambda row: deg_centrality[row.target_id], axis = 1)\n",
    "\n",
    "training['source_k_core'] = training.apply(lambda row: k_core[row.source_id], axis = 1)\n",
    "training['target_k_core'] = training.apply(lambda row: k_core[row.target_id], axis = 1)\n",
    "\n",
    "# Preferential Attachment\n",
    "training['pref_attach_directed'] = training.apply(lambda row: row.source_out_centrality * row.target_in_centrality, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf066d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.54 s, sys: 34.9 ms, total: 1.58 s\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['source_in_centrality'] = testing.apply(lambda row: in_degree_centrality[row.source_id], axis = 1)\n",
    "testing['source_out_centrality'] = testing.apply(lambda row: out_degree_centrality[row.source_id], axis = 1)\n",
    "testing['target_in_centrality'] = testing.apply(lambda row: in_degree_centrality[row.target_id], axis = 1)\n",
    "testing['target_out_centrality'] = testing.apply(lambda row: out_degree_centrality[row.target_id], axis = 1)\n",
    "\n",
    "testing['source_degree_centrality'] = testing.apply(lambda row: deg_centrality[row.source_id], axis = 1)\n",
    "testing['target_degree_centrality'] = testing.apply(lambda row: deg_centrality[row.target_id], axis = 1)\n",
    "\n",
    "testing['source_k_core'] = testing.apply(lambda row: k_core[row.source_id], axis = 1)\n",
    "testing['target_k_core'] = testing.apply(lambda row: k_core[row.target_id], axis = 1)\n",
    "\n",
    "# Preferential Attachment\n",
    "testing['pref_attach_directed'] = testing.apply(lambda row: row.source_out_centrality * row.target_in_centrality, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21741aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITS algorithm\n",
    "hub_score, authority_score = nx.hits(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c44c10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 363 ms, total: 13.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training['source_hub_score'] = training.apply(lambda row: hub_score[row.source_id], axis = 1)\n",
    "training['target_hub_score'] = training.apply(lambda row: hub_score[row.target_id], axis = 1)\n",
    "testing['source_hub_score'] = testing.apply(lambda row: hub_score[row.source_id], axis = 1)\n",
    "testing['target_hub_score'] = testing.apply(lambda row: hub_score[row.target_id], axis = 1)\n",
    "\n",
    "training['source_authority_score'] = training.apply(lambda row: authority_score[row.source_id], axis = 1)\n",
    "training['target_authority_score'] = training.apply(lambda row: authority_score[row.target_id], axis = 1)\n",
    "testing['target_authority_score'] = testing.apply(lambda row: authority_score[row.target_id], axis = 1)\n",
    "testing['source_authority_score'] = testing.apply(lambda row: authority_score[row.source_id], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec586610",
   "metadata": {},
   "source": [
    "### Undirected Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a22929",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_ud = G.to_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "859b9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaccobian Index\n",
    "def jacc_index(G, source, target):\n",
    "    jacc = 0\n",
    "    if (source not in G.nodes() or target not in G.nodes()):\n",
    "        return -1\n",
    "    preds = nx.jaccard_coefficient(G, [(source, target)])\n",
    "    for _, _, jacc in preds:\n",
    "        return jacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6642ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "training['jacc_index'] = training.apply(lambda row: jacc_index(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c414db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 55.9 ms, total: 1.51 s\n",
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['jacc_index'] = testing.apply(lambda row: jacc_index(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea0993ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.04 s, sys: 101 ms, total: 7.14 s\n",
      "Wall time: 7.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Preferencial Attachment\n",
    "def pref_attach(G, source, target):\n",
    "    if (source not in G.nodes() or target not in G.nodes()):\n",
    "        return -1\n",
    "    preds = nx.preferential_attachment(G, [(source, target)])\n",
    "    for _, _, pref in preds:\n",
    "        return pref\n",
    "\n",
    "training['pref_attach_undirected'] = training.apply(lambda row: pref_attach(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "10d0ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 402 ms, sys: 11.6 ms, total: 414 ms\n",
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['pref_attach_undirected'] = testing.apply(lambda row: pref_attach(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d46bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>target_id</th>\n",
       "      <th>Y</th>\n",
       "      <th>source_year</th>\n",
       "      <th>source_authors</th>\n",
       "      <th>source_title</th>\n",
       "      <th>source_jn</th>\n",
       "      <th>source_abstract</th>\n",
       "      <th>target_year</th>\n",
       "      <th>target_authors</th>\n",
       "      <th>...</th>\n",
       "      <th>source_out_centrality</th>\n",
       "      <th>target_in_centrality</th>\n",
       "      <th>target_out_centrality</th>\n",
       "      <th>source_degree_centrality</th>\n",
       "      <th>target_degree_centrality</th>\n",
       "      <th>source_k_core</th>\n",
       "      <th>target_k_core</th>\n",
       "      <th>pref_attach_directed</th>\n",
       "      <th>jacc_index</th>\n",
       "      <th>pref_attach_undirected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9510123</td>\n",
       "      <td>9502114</td>\n",
       "      <td>1</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>infinit number potenti surround 2d black hole</td>\n",
       "      <td>phys.lett.</td>\n",
       "      <td>found infinit number potenti surround 2d black...</td>\n",
       "      <td>1995</td>\n",
       "      <td>won t. kim,julian lee,young jai park</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.112367e-08</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   source_id  target_id  Y  source_year source_authors  \\\n",
       "0    9510123    9502114  1         1995            NaN   \n",
       "\n",
       "                                    source_title   source_jn  \\\n",
       "0  infinit number potenti surround 2d black hole  phys.lett.   \n",
       "\n",
       "                                     source_abstract  target_year  \\\n",
       "0  found infinit number potenti surround 2d black...         1995   \n",
       "\n",
       "                         target_authors  ... source_out_centrality  \\\n",
       "0  won t. kim,julian lee,young jai park  ...              0.000108   \n",
       "\n",
       "  target_in_centrality target_out_centrality  source_degree_centrality  \\\n",
       "0             0.000288              0.000144                  0.000216   \n",
       "\n",
       "   target_degree_centrality  source_k_core  target_k_core  \\\n",
       "0                  0.000432              5              8   \n",
       "\n",
       "   pref_attach_directed  jacc_index  pref_attach_undirected  \n",
       "0          3.112367e-08    0.058824                      72  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2832478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 s, sys: 144 ms, total: 21.4 s\n",
      "Wall time: 21.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Common Neighbors and Common Neighbors Count\n",
    "def common_neighbors(G, source, target):\n",
    "    if (source not in G.nodes() or target not in G.nodes):\n",
    "        return -1\n",
    "    neighbors = list(nx.common_neighbors(G, source, target))\n",
    "    return len(neighbors)\n",
    "\n",
    "training['common_neighbors'] = training.apply(lambda row: common_neighbors(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "80d13334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.14 s, sys: 13 ms, total: 1.15 s\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['common_neighbors'] = testing.apply(lambda row: common_neighbors(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d394db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_neighbors_b(cn):\n",
    "    if cn > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7f647f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training['common_neighbors_b'] = training.apply(lambda row: common_neighbors_b(row.common_neighbors), axis = 1)\n",
    "testing['common_neighbors_b'] = testing.apply(lambda row: common_neighbors_b(row.common_neighbors), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1596281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 s, sys: 120 ms, total: 25.8 s\n",
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Adamic Adar Index\n",
    "def adamic_adar(G, source, target):\n",
    "    if (source not in G.nodes() or target not in G.nodes()):\n",
    "        return -1\n",
    "    preds = nx.adamic_adar_index(G, [(source, target)])\n",
    "    for _, _, aa in preds:\n",
    "        return aa\n",
    "\n",
    "training['adamic_adar'] = training.apply(lambda row: adamic_adar(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "933a1a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 17.3 ms, total: 1.44 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['adamic_adar'] = testing.apply(lambda row: adamic_adar(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeb64b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 36s, sys: 1.15 s, total: 4min 37s\n",
      "Wall time: 4min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Distance Between Nodes\n",
    "def shortest_path(G, source, target, k=2):\n",
    "    try:\n",
    "        paths = list(islice(nx.shortest_simple_paths(G, source, target), k))\n",
    "    except:\n",
    "        return -1\n",
    "    paths = nx.shortest_simple_paths(G, source, target)\n",
    "    for path in paths:\n",
    "        if len(path)!=2:\n",
    "            return len(path)\n",
    "    return -1\n",
    "\n",
    "training['distance_nodes'] = training.apply(lambda row: shortest_path(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db44a87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 s, sys: 80.2 ms, total: 15.6 s\n",
      "Wall time: 15.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['distance_nodes'] = testing.apply(lambda row: shortest_path(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "607da284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 57s, sys: 2.32 s, total: 7min 59s\n",
      "Wall time: 7min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def shortest_path2(G, source, target, k=3):\n",
    "    c=0\n",
    "    try:\n",
    "        paths = list(islice(nx.shortest_simple_paths(G, source, target), k))\n",
    "    except:\n",
    "        return -1\n",
    "    for path in paths:\n",
    "        if len(path)!=2:\n",
    "            c+=1\n",
    "            if c==2:\n",
    "                return len(path)\n",
    "    return -1\n",
    "\n",
    "\n",
    "training['distance_nodes2'] = training.apply(lambda row: shortest_path2(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "38a212cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 s, sys: 133 ms, total: 26.8 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['distance_nodes2'] = testing.apply(lambda row: shortest_path2(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98a7d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 5s, sys: 3.2 s, total: 12min 9s\n",
      "Wall time: 12min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def shortest_path3(G, source, target, k=4):\n",
    "    c=0\n",
    "    try:\n",
    "        paths = list(islice(nx.shortest_simple_paths(G, source, target), k))\n",
    "    except:\n",
    "        return -1\n",
    "    for path in paths:\n",
    "        if len(path)!=2:\n",
    "            c+=1\n",
    "            if c==3:\n",
    "                return len(path)\n",
    "    return -1\n",
    "\n",
    "training['distance_nodes3'] = training.apply(lambda row: shortest_path3(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f9ca062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.3 s, sys: 181 ms, total: 40.4 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "testing['distance_nodes3'] = testing.apply(lambda row: shortest_path3(G_ud, row.source_id, row.target_id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd090119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page rank\n",
    "page_rank = nx.pagerank(G)\n",
    "training['target_pagerank'] = training.apply(lambda row: page_rank[row.target_id], axis = 1)\n",
    "testing['target_pagerank'] = testing.apply(lambda row: page_rank[row.target_id], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973ff559",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96473f19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3813938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv(\"../data/final_trainig_set1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d1aaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv(\"../data/final_testing_set1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105c90d",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ba1441bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_training = pd.read_csv(\"../data/final_trainig_set1.csv\")\n",
    "temp_testing = pd.read_csv(\"../data/final_testing_set1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "656f008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv(\"../data/final_trainig_set.csv\")\n",
    "testing = pd.read_csv(\"../data/final_testing_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7b311eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = temp_training.drop(labels=['source_year','source_authors',\n",
    "                                    'source_title','source_jn','source_abstract',\n",
    "                                    'target_year','target_authors',\n",
    "                                    'target_title','target_jn','target_abstract'], axis=1)\n",
    "testing_df = temp_testing.drop(labels=['source_year','source_authors',\n",
    "                                    'source_title','source_jn','source_abstract',\n",
    "                                    'target_year','target_authors',\n",
    "                                    'target_title','target_jn','target_abstract'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5ab0d35a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "31\n",
      "Index(['source_id', 'target_id', 'Y', 'year_diff', 'common_authors',\n",
      "       'same_journal', 'title_similarity', 'abstract_similarity',\n",
      "       'source_in_centrality', 'source_out_centrality', 'target_in_centrality',\n",
      "       'target_out_centrality', 'source_degree_centrality',\n",
      "       'target_degree_centrality', 'source_k_core', 'target_k_core',\n",
      "       'pref_attach_directed', 'jacc_index', 'pref_attach_undirected',\n",
      "       'common_neighbors', 'adamic_adar', 'distance_nodes', 'distance_nodes2',\n",
      "       'distance_nodes3', 'target_pagerank', 'source_hub_score',\n",
      "       'target_authority_score', 'target_hub_score', 'source_authority_score',\n",
      "       'common_neighbors_b', 'title_embed_sim', 'abstract_embed_sim'],\n",
      "      dtype='object')\n",
      "Index(['source_id', 'target_id', 'year_diff', 'common_authors', 'same_journal',\n",
      "       'title_similarity', 'abstract_similarity', 'source_in_centrality',\n",
      "       'source_out_centrality', 'target_in_centrality',\n",
      "       'target_out_centrality', 'source_degree_centrality',\n",
      "       'target_degree_centrality', 'source_k_core', 'target_k_core',\n",
      "       'pref_attach_directed', 'jacc_index', 'pref_attach_undirected',\n",
      "       'common_neighbors', 'adamic_adar', 'distance_nodes', 'distance_nodes2',\n",
      "       'distance_nodes3', 'target_pagerank', 'source_hub_score',\n",
      "       'target_authority_score', 'target_hub_score', 'source_authority_score',\n",
      "       'common_neighbors_b', 'title_embed_sim', 'abstract_embed_sim'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(training_df.columns))\n",
    "print(len(testing_df.columns))\n",
    "\n",
    "\n",
    "print(training_df.columns)\n",
    "print(testing_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b021e38b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id                                                       9701033\n",
       "Y                                                                     0\n",
       "source_title                       quantum gravit measur three-geometri\n",
       "target_title          israel condit gauss-bonnet theori friedmann equat\n",
       "source_abstract       modif publish gravit measur arbitrari topolog ...\n",
       "target_abstract       brane univers addit bulk field assum einstein-...\n",
       "title_embed_sim                                                 0.17473\n",
       "abstract_embed_sim                                             0.730622\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[['source_id','Y','source_title','target_title','source_abstract','target_abstract','title_embed_sim','abstract_embed_sim']].loc[4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2b05d901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_abstract</th>\n",
       "      <th>target_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>found infinit number potenti surround 2d black...</td>\n",
       "      <td>explicitli show net number degre freedom two-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>winter school dualiti mt sorak korea februari ...</td>\n",
       "      <td>construct sever exampl compactif type iib theo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>examin correspond conform field theori boundar...</td>\n",
       "      <td>reissner-nordstr om black hole result follow h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>supersymmetr scale invari theori discuss gener...</td>\n",
       "      <td>show dijkgraaf-vafa matrix model propos extend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modif publish gravit measur arbitrari topolog ...</td>\n",
       "      <td>brane univers addit bulk field assum einstein-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615507</th>\n",
       "      <td>non-perturb method quantis light-con le houch ...</td>\n",
       "      <td>kresimir puhep1 princeton edu pupt-1427 iassns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615508</th>\n",
       "      <td>investig scatter electron infinit thin infinit...</td>\n",
       "      <td>studi metric minim area punctur riemann surfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615509</th>\n",
       "      <td>construct boundari state d-brane su 2 group ma...</td>\n",
       "      <td>method construct canon gaug invari quantum for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615510</th>\n",
       "      <td>start n 1 scalar supermultiplet 2 1 dimens bui...</td>\n",
       "      <td>model bled slovenia juli 17-27 2001 old idea p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615511</th>\n",
       "      <td>discuss possibl relat singleton ad space logar...</td>\n",
       "      <td>correspond string theori anti-d sitter space s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615512 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_abstract  \\\n",
       "0       found infinit number potenti surround 2d black...   \n",
       "1       winter school dualiti mt sorak korea februari ...   \n",
       "2       examin correspond conform field theori boundar...   \n",
       "3       supersymmetr scale invari theori discuss gener...   \n",
       "4       modif publish gravit measur arbitrari topolog ...   \n",
       "...                                                   ...   \n",
       "615507  non-perturb method quantis light-con le houch ...   \n",
       "615508  investig scatter electron infinit thin infinit...   \n",
       "615509  construct boundari state d-brane su 2 group ma...   \n",
       "615510  start n 1 scalar supermultiplet 2 1 dimens bui...   \n",
       "615511  discuss possibl relat singleton ad space logar...   \n",
       "\n",
       "                                          target_abstract  \n",
       "0       explicitli show net number degre freedom two-d...  \n",
       "1       construct sever exampl compactif type iib theo...  \n",
       "2       reissner-nordstr om black hole result follow h...  \n",
       "3       show dijkgraaf-vafa matrix model propos extend...  \n",
       "4       brane univers addit bulk field assum einstein-...  \n",
       "...                                                   ...  \n",
       "615507  kresimir puhep1 princeton edu pupt-1427 iassns...  \n",
       "615508  studi metric minim area punctur riemann surfac...  \n",
       "615509  method construct canon gaug invari quantum for...  \n",
       "615510  model bled slovenia juli 17-27 2001 old idea p...  \n",
       "615511  correspond string theori anti-d sitter space s...  \n",
       "\n",
       "[615512 rows x 2 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training[['source_abstract','target_abstract']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c86dbc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_df.drop(columns = 'Y')\n",
    "y = training_df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "356d626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, random_state = 41)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d26ff",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28414fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlns_env/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:06:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 1h 9min 9s, sys: 8min 48s, total: 1h 17min 58s\n",
      "Wall time: 10min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.1, max_delta_step=0,\n",
       "              max_depth=25, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=1000, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb = XGBClassifier(learning_rate = 0.1, n_estimators = 1000, max_depth = 25)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0750151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34d5eedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9816732113543262"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be975b9",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a492865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBMClassifier1(X_train, y_train):\n",
    "\n",
    "    grid_params = {'n_estimators': [1175, 1200, 1250],\n",
    "                   'num_leaves': [250, 300, 350],\n",
    "                   'min_child_samples': [80, 100]}\n",
    "\n",
    "    rf_clf = LGBMClassifier()\n",
    "\n",
    "    rf_cv = GridSearchCV(estimator = rf_clf, \n",
    "                         param_grid=grid_params, \n",
    "                         cv =5, \n",
    "                         verbose=1, \n",
    "                         scoring = 'f1_weighted', \n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    rf_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"best_score_\", rf_cv.best_score_)\n",
    "    print(\"best_params_\", rf_cv.best_params_)\n",
    "    \n",
    "    rf_best = rf_cv.best_estimator_\n",
    "    return rf_best\n",
    "#     y_predicted = rf_best.predict(X_test)\n",
    "#     rf_accuracy = accuracy_score(y_test, y_predicted)\n",
    "#     rf_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "#     print(\"rf_accuracy, rf_f1\", rf_accuracy, rf_f1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c7d7af16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "best_score_ 0.9826634917355946\n",
      "best_params_ {'min_child_samples': 80, 'n_estimators': 1250, 'num_leaves': 250}\n",
      "CPU times: user 4min 5s, sys: 55 s, total: 5min\n",
      "Wall time: 39min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm = lightGBMClassifier1(X,y)\n",
    "\n",
    "# best_score_ 0.9808501773477625\n",
    "# best_params_ {'min_child_samples': 90, 'n_estimators': 1100, 'num_leaves': 400}\n",
    "\n",
    "# best_score_ 0.9808827083203641\n",
    "# best_params_ {'min_child_samples': 80, 'n_estimators': 1200, 'num_leaves': 405}\n",
    "\n",
    "# best_score_ 0.9808940299134872\n",
    "# best_params_ {'min_child_samples': 81, 'n_estimators': 1250, 'num_leaves': 405}\n",
    "\n",
    "# best_score_ 0.9809020231922009\n",
    "# best_params_ {'min_child_samples': 82, 'n_estimators': 1250, 'num_leaves': 406}\n",
    "\n",
    "# best_score_ 0.9809166500036139\n",
    "# best_params_ {'min_child_samples': 82, 'n_estimators': 1252, 'num_leaves': 406}\n",
    "\n",
    "# best_score_ 0.980924780052322\n",
    "# best_params_ {'min_child_samples': 82, 'n_estimators': 1256, 'num_leaves': 406}\n",
    "\n",
    "\n",
    "# Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "# best_score_ 0.9826454820577499\n",
    "# best_params_ {'min_child_samples': 80, 'n_estimators': 1200, 'num_leaves': 350}\n",
    "# CPU times: user 4min 49s, sys: 1min 3s, total: 5min 52s\n",
    "# Wall time: 44min 34s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "629a904b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(min_child_samples=82, n_estimators=1256, num_leaves=406)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = LGBMClassifier(min_child_samples=82, n_estimators=1256, num_leaves=406)\n",
    "gbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0273ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "ypreds = gbm.predict(X_test)\n",
    "print(accuracy_score(y_test, ypreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c038df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30974ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7d3026bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightGBMClassifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    grid_params = {'n_estimators': [300, 500, 700],\n",
    "                   'num_leaves': [100, 150, 200],\n",
    "                   'min_child_samples': [50, 100, 150]}\n",
    "\n",
    "    rf_clf = LGBMClassifier()\n",
    "\n",
    "    rf_cv = GridSearchCV(estimator = rf_clf, \n",
    "                         param_grid=grid_params, \n",
    "                         cv =2, \n",
    "                         verbose=2, \n",
    "                         scoring = 'f1_weighted', \n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    rf_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"rf_cv.best_params_\", rf_cv.best_params_)\n",
    "    \n",
    "    rf_best = rf_cv.best_estimator_\n",
    "    y_predicted = rf_best.predict(X_test)\n",
    "    rf_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    rf_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "    print(\"rf_accuracy, rf_f1\", rf_accuracy, rf_f1)\n",
    "\n",
    "    return rf_accuracy, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ec505bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n",
      "rf_cv.best_params_ {'min_child_samples': 100, 'n_estimators': 500, 'num_leaves': 200}\n",
      "rf_accuracy, rf_f1 0.9801899769298255 0.9801950694901748\n",
      "CPU times: user 1min 15s, sys: 14.4 s, total: 1min 29s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,f = lightGBMClassifier(X_train, X_test, y_train, y_test)\n",
    "# rf_cv.best_params_ {'min_child_samples': 100, 'n_estimators': 500, 'num_leaves': 200}\n",
    "# rf_accuracy, rf_f1 0.9801899769298255 0.9801950694901748"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd0495a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce107370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 9.88 s, total: 1min 10s\n",
      "Wall time: 9.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(min_child_samples=100, n_estimators=500, num_leaves=200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gbm = LGBMClassifier(num_leaves = 200, n_estimators = 500, min_child_samples = 100)\n",
    "gbm.fit(X_train, y_train)\n",
    "# LGBMClassifier(min_child_samples=100, n_estimators=500, num_leaves=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "603f3e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9817532448098009"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gbm.predict(X_test)\n",
    "f1_score(y_pred, y_test)\n",
    "\n",
    "# 0.9810149635018287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7c601f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 21 s, total: 1min 38s\n",
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(min_child_samples=100, n_estimators=500, num_leaves=200)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gbm = LGBMClassifier(num_leaves = 200, n_estimators = 500, min_child_samples = 100)\n",
    "gbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f091a7",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f16b8a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForestClassifier1(X_train, y_train):\n",
    "\n",
    "    grid_params = {'n_estimators': [ 390, 400, 410],\n",
    "                   'max_depth': [90, 100, 110],\n",
    "                   'min_samples_leaf': [1]}\n",
    "\n",
    "    rf_clf = RandomForestClassifier()\n",
    "\n",
    "    rf_cv = GridSearchCV(estimator = rf_clf, \n",
    "                         param_grid=grid_params, \n",
    "                         cv =5, \n",
    "                         verbose=1, \n",
    "                         scoring = 'f1_weighted', \n",
    "                         n_jobs=-1)\n",
    "    \n",
    "    rf_cv.fit(X_train, y_train.values.ravel())\n",
    "    print(\"best_score_\", rf_cv.best_score_)\n",
    "    print(\"best_params_\", rf_cv.best_params_)\n",
    "    \n",
    "    rf_best = rf_cv.best_estimator_\n",
    "    return rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a46f98fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "best_score_ 0.9797905267316376\n",
      "best_params_ {'max_depth': 110, 'min_samples_leaf': 1, 'n_estimators': 410}\n",
      "CPU times: user 10min 9s, sys: 1.93 s, total: 10min 11s\n",
      "Wall time: 1h 30min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = randomForestClassifier1(X, y)\n",
    "\n",
    "# best_score_ 0.9793063101578294\n",
    "# best_params_ {'max_depth': 110, 'min_samples_leaf': 1, 'n_estimators': 400}\n",
    "\n",
    "# best_score_ 0.9792916555649237\n",
    "# best_params_ {'max_depth': 108, 'min_samples_leaf': 1, 'n_estimators': 400}\n",
    "\n",
    "# best_score_ 0.9799314414321392\n",
    "# best_params_ {'max_depth': 50, 'min_samples_leaf': 1, 'n_estimators': 450}\n",
    "\n",
    "# Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
    "# best_score_ 0.9797498064066816\n",
    "# best_params_ {'max_depth': 100, 'min_samples_leaf': 1, 'n_estimators': 400}\n",
    "# CPU times: user 9min 59s, sys: 2.8 s, total: 10min 1s\n",
    "# Wall time: 5h 6min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7a2c96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50, n_estimators=450)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad9b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b3cebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def randomForestClassifier(X_train, X_test, y_train, y_test):\n",
    "\n",
    "#     grid_params = {'n_estimators': [450, 500, 550],\n",
    "#                    'max_depth': [153, 155, 157],\n",
    "#                    'min_samples_leaf': [1]}\n",
    "\n",
    "#     rf_clf = RandomForestClassifier()\n",
    "\n",
    "#     rf_cv = GridSearchCV(estimator = rf_clf, \n",
    "#                          param_grid=grid_params, \n",
    "#                          cv =2, \n",
    "#                          verbose=2, \n",
    "#                          scoring = 'f1_weighted', \n",
    "#                          n_jobs=-1)\n",
    "    \n",
    "#     rf_cv.fit(X_train, y_train.values.ravel())\n",
    "#     print(\"rf_cv.best_params_\", rf_cv.best_params_)\n",
    "    \n",
    "#     rf_best = rf_cv.best_estimator_\n",
    "#     y_predicted = rf_best.predict(X_test)\n",
    "#     rf_accuracy = accuracy_score(y_test, y_predicted)\n",
    "#     rf_f1 = f1_score(y_test, y_predicted, average=\"weighted\")\n",
    "#     print(\"rf_accuracy, rf_f1\", rf_accuracy, rf_f1)\n",
    "\n",
    "#     return rf_accuracy, rf_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6c655623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# a,f = randomForestClassifier(X_train, X_test, y_train, y_test)\n",
    "# print(\"a =\", a)\n",
    "# print(\"f =\", f)\n",
    "\n",
    "# # rf_cv.best_params_ {'max_depth': 155, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
    "# # rf_accuracy, rf_f1 0.9784570060762291 0.9784663816673383\n",
    "\n",
    "# # rf_cv.best_params_ {'max_depth': 153, 'min_samples_leaf': 1, 'n_estimators': 500}\n",
    "# # rf_accuracy, rf_f1 0.9784028507370541 0.9784122498967688"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e75882a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# rf = RandomForestClassifier(max_depth= 153, min_samples_leaf= 1, n_estimators= 500)\n",
    "# rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = rf.predict(X_test)\n",
    "# f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afb2dc",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1f2eb4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(min_child_samples=80, n_estimators=1250, num_leaves=250)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "8cba884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submodel = gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c748c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = list(submodel.predict(testing_df))\n",
    "data = {'id': range(len(y_pred)), 'category': y_pred}\n",
    "submission = pd.DataFrame(data).set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "898c05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('gbmsubmission2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c2e81e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17075\n",
       "0    15573\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "609eafc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    16981\n",
       "0    15667\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "deed3ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    8,    16,    21,    24,    25,    29,    32,    35,    37,\n",
       "               42,\n",
       "            ...\n",
       "            32608, 32610, 32613, 32621, 32629, 32630, 32639, 32641, 32644,\n",
       "            32646],\n",
       "           dtype='int64', length=6977)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing[testing['source_year'] < testing['target_year']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c4b9239b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_id                                                             9603027\n",
       "target_id                                                              301251\n",
       "source_year                                                              1996\n",
       "source_authors                                        choonkyu lee,q-han park\n",
       "source_title                                    gravit bp dyon witout dilaton\n",
       "source_jn                                                          phys.lett.\n",
       "source_abstract             describ curved-spac bp dyon solut adm mass sat...\n",
       "target_year                                                              2003\n",
       "target_authors                        v.p. akulov,oktay cebecioglu,a. pashnev\n",
       "target_title                     superconform quantum mechan nonlinear realiz\n",
       "target_jn                                                                 NaN\n",
       "target_abstract             approach framework nonlinear realiz reder acti...\n",
       "year_diff                                                                  -1\n",
       "common_authors                                                              0\n",
       "same_journal                                                                0\n",
       "title_similarity                                                          0.0\n",
       "abstract_similarity                                                       0.0\n",
       "source_in_centrality                                                      0.0\n",
       "source_out_centrality                                                0.000072\n",
       "target_in_centrality                                                 0.000036\n",
       "target_out_centrality                                                0.000216\n",
       "source_degree_centrality                                             0.000072\n",
       "target_degree_centrality                                             0.000252\n",
       "source_k_core                                                               2\n",
       "target_k_core                                                               6\n",
       "pref_attach_directed                                                      0.0\n",
       "jacc_index                                                                0.0\n",
       "pref_attach_undirected                                                     14\n",
       "common_neighbors                                                            0\n",
       "adamic_adar                                                               0.0\n",
       "distance_nodes                                                              5\n",
       "distance_nodes2                                                             6\n",
       "distance_nodes3                                                             6\n",
       "target_pagerank                                                      0.000012\n",
       "source_hub_score                                                          0.0\n",
       "target_authority_score                                                    0.0\n",
       "target_hub_score                                                     0.000002\n",
       "source_authority_score                                                   -0.0\n",
       "common_neighbors_b                                                      False\n",
       "title_embed_sim                                                      0.446063\n",
       "abstract_embed_sim                                                   0.549866\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.loc[8,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d956a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nolink = testing[testing['source_year'] < testing['target_year']].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "cfe58e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    8,    16,    21,    24,    25,    29,    32,    35,    37,\n",
      "               42,\n",
      "            ...\n",
      "            32608, 32610, 32613, 32621, 32629, 32630, 32639, 32641, 32644,\n",
      "            32646],\n",
      "           dtype='int64', length=6977)\n"
     ]
    }
   ],
   "source": [
    "print(nolink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "97bce1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6977"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nolink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2746bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8cbae917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submission.loc[nolink,:].loc[ (submission.category > 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1681cf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30431</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31044</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31818</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32005</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32408</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       category\n",
       "id             \n",
       "53            1\n",
       "126           1\n",
       "624           1\n",
       "784           1\n",
       "815           1\n",
       "...         ...\n",
       "30431         1\n",
       "31044         1\n",
       "31818         1\n",
       "32005         1\n",
       "32408         1\n",
       "\n",
       "[116 rows x 1 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[nolink][submission.iloc[nolink]['category'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5efe5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[nolink,'category'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b38ea3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [category]\n",
       "Index: []"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.iloc[nolink][submission.iloc[nolink]['category'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c4b2c568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32648, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce64a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b42477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779ab0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00bb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca2340f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d93f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130824f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
